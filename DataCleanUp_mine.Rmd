---
title: "Eyetracking"
author: '"Anita Kurm"'
date: '5 ??????? 2018 ? '
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#libraries
pacman::p_load(dplyr,readr,groupdata2,ggplot2,tidyverse, lme4, MuMIn, lmerTest, gstat, caret, simr, ModelMetrics, Metrics, MASS, pacman, modelr, plyr, stringr, data.table)

#set wd
setwd("C:/Users/JARVIS/Desktop/Uni/Semester 4/Computational modelling/Portfolio-1-Eye-tracking")

#load the data, TAKES SOME TIME TO DOWNLOAD, DON'T DO IT IF NOT NECESSARY
#Samples=read_delim('eyetracking_2018_samples.txt',delim='\t')
#Fixations=read_delim('eyetracking_2018_fixations.txt',delim='\t')
#Saccades=read_delim('eyetracking_2018_saccades.txt',delim='\t')

#data files have data from both experiemts!

#data from v1. csv
FixationsV1=read_delim('FixationsV1.csv',delim=',')
SaccadesV1=read_delim('SaccadesV1.csv',delim=',')
SamplesV1=read_delim('SamplesV1.csv',delim=',')

#logfiles
setwd("C:/Users/JARVIS/Desktop/Uni/Semester 4/Computational modelling/Portfolio-1-Eye-tracking/PupilsLogs")

file_list <- list.files()
dataset<-NULL
 
#merge all of the log datafiles into one dataset
for (file in file_list){
       
  # if the merged dataset doesn't exist, create it
  if (!exists("dataset")){
    dataset <- read.table(file, header=TRUE, sep=",")
  }
   
  # if the merged dataset does exist, append to it
  if (exists("dataset")){
    temp_dataset <-read.table(file, header=TRUE, sep=",")
    dataset<-rbind(dataset, temp_dataset)
    rm(temp_dataset)
  }
 
}

#add 1 to X (trial)
dataset$X<-dataset$X+1
dataset$X<-dataset$Trial
dataset$X<-NULL

#change the names of the columns in the log files dataset
setnames(dataset,"subject", "ParticipantID")

#Merge logfiles
SaccadesV1_new<-merge(SaccadesV1,dataset, all = T)
FixationsV1_new<-merge(FixationsV1,dataset, all = T)
SamplesV1_new<-merge(SamplesV1,dataset,all=T)


#trials below 6, in search order 1 -> stars
#trials below 6, in serach order 2 -> count

SaccadesV1_new$SearchType<-NA
SaccadesV1_new$SearchType[SaccadesV1_new$Trial <6 & SaccadesV1_new$SearchOrder == 1] <- 'Star'
SaccadesV1_new$SearchType[SaccadesV1_new$Trial >=6 & SaccadesV1_new$SearchOrder == 1] <- 'Count'
SaccadesV1_new$SearchType[SaccadesV1_new$Trial <6 & SaccadesV1_new$SearchOrder == 2] <- 'Count'
SaccadesV1_new$SearchType[SaccadesV1_new$Trial >=6 & SaccadesV1_new$SearchOrder == 2] <- 'Star'

FixationsV1_new$SearchType<-NA
FixationsV1_new$SearchType[FixationsV1_new$Trial <6 & FixationsV1_new$SearchOrder == 1] <- 'Star'
FixationsV1_new$SearchType[FixationsV1_new$Trial >=6 & FixationsV1_new$SearchOrder == 1] <- 'Count'
FixationsV1_new$SearchType[FixationsV1_new$Trial <6 & FixationsV1_new$SearchOrder == 2] <- 'Count'
FixationsV1_new$SearchType[FixationsV1_new$Trial >=6 & FixationsV1_new$SearchOrder == 2] <- 'Star'

SamplesV1_new$SearchType<-NA
SamplesV1_new$SearchType[SamplesV1_new$Trial <6 & SamplesV1_new$SearchOrder == 1] <- 'Star'
SamplesV1_new$SearchType[SamplesV1_new$Trial >=6 & SamplesV1_new$SearchOrder == 1] <- 'Count'
SamplesV1_new$SearchType[SamplesV1_new$Trial <6 & SamplesV1_new$SearchOrder == 2] <- 'Count'
SamplesV1_new$SearchType[SamplesV1_new$Trial >=6 & SamplesV1_new$SearchOrder == 2] <- 'Star'


#new V1 datafiles are V2 datafiles in the folder
#always visualize and look at the data to spot abnormalities, etc.

#create a model to test the hypothesis: Visual search patterns are affaceted by task structure and goals
# predict the type of the task by variables of fixation duration, position, etc.d

#models
#model1<- Duration~SearchType+Trial+(1|ParticipantID)
#FAMILY=Gaussian(link=log) <-- data log trasnformation, helps to normalize skewed dataset

#so we have three models, use crossvalidation (3 folds) to see which one is the best

#make CROSS-VALIDATION

#Make variables into factors
FixationsV1_new$ParticipantID = as.factor(FixationsV1_new$ParticipantID)

  #folds first
Folds<- createFolds(unique(FixationsV1_new$ParticipantID),k=3)
Folds

#Create ID as numbers for use in folding
FixationsV1_new$fold_id = as.numeric(FixationsV1_new$ParticipantID)

#Preperations for loop - result lists and n reset
rmse_train = NULL
rmse_test = NULL
n=1


  #loop through each fold, train a model on the other folds and test it on the fold), thanks Peter!


#THE LOOP FOR THE BASIC MODEL  
for (i in Folds) {
  #Make a test dataset with one fold
  dtest_temp = subset(subset(FixationsV1_new, Task=="VisualSearch"), fold_id %in% i)
  #Make a training dataset with all other folds
  dtrain_temp = subset(subset(FixationsV1_new, Task=="VisualSearch"), !fold_id %in% i)
  
  #View(dtest_temp)
  #View(dtrain_temp)
  #Make a model on the training dataset
  Model_temp = lmer(Duration~SearchType+Trial+(1+SearchType+Trial|ParticipantID), data = dtrain_temp)
  
  #Check error between fit of training data and actual training data
  rmse_train[n] = Metrics :: rmse(dtrain_temp$Duration, fitted(Model_temp))
  
  #Check error between predicitions for test data and actual test data
  rmse_test[n] = Metrics :: rmse(dtest_temp$Duration, predict(Model_temp, dtest_temp, allow.new.levels=T)) 

    #Loop end and n+1
  n=n+1
}

#Get results
rmse_train
mean(rmse_train) #191.0751

rmse_test
mean(rmse_test) #201.8306
```




bla bla 
```{r}
###########CROSS-VALIDATION################# doesn't work.. contrasts error
#Preperations for loop - result lists and n reset
rmse_train = NULL
rmse_test = NULL
n=1


#Create list of the models to test
Ms = c("Duration~SearchType+Trial+(1+SearchType+Trial|ParticipantID)",
       "Duration~SearchType+Fixation+(1+SearchType+Fixation|ParticipantID)",
       "Duration~SearchType+SearchOrder+(1+SearchType+SearchOrder|ParticipantID)"
       )

#Create lists for results
SCORES = as.data.frame(NULL)

#Create ID as numbers for use in folding
data$fold_id = as.numeric(FixationsV1_new$ParticipantID)

#Run Loop for all models
for (M in Ms) {
  #Create folds
  Folds = createFolds(unique(FixationsV1_new$fold_id), 3)
  #Preperations for loop - result lists and n reset
  rmse_train = NULL
  rmse_test = NULL
  n=1
  
  for (i in Folds) {
    #Make a test dataset with one fold
    dtest_temp = subset(subset(FixationsV1_new, Task=="VisualSearch"), fold_id %in% i)
    #Make a training dataset with all other folds
    dtrain_temp = subset(subset(FixationsV1_new, Task=="VisualSearch"), !fold_id %in% i)
    
    #View(dtest_temp)
    #View(dtrain_temp)
    #Make a model on the training dataset
    FixationsV1_new$ParticipantID=as.factor(FixationsV1_new$ParticipantID)
    model_temp = glmer(M, dtrain_temp, family = gaussian(link = log))
    
    #Check error between fit of training data and actual training data
    rmse_train[n] = Metrics :: rmse(dtrain_temp$Duration, fitted(model_temp))
    
    #Check error between predicitions for test data and actual test data
    rmse_test[n] = Metrics :: rmse(dtest_temp$Duration, predict(model_temp, dtest_temp, allow.new.levels=T)) 
  
      #Loop end and n+1
    n=n+1
  }
 #Create row with results from model
  NewRow = data.frame(Model = M, rmse_train = mean(rmse_train), rmse_test = mean(rmse_test))
  #Add to final dataframe with all models
  SCORES = rbind(SCORES, NewRow) 
}


#pupil size models - polinomial cubic model is probably the best (^3) for the social engagement task
SCORES



#VISUAL REPRESENTATIONs
#Visual search experiment:
#Fixation duration <-heat maps, x and y = positions, colors = datapoints density 
setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking")
FixationsV2<- read.csv("FixationsV2.csv")
#libraries
library(jpeg)
library(grid)
library(ggplot2)

#choose the pallette
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))

#define the image for the graph background
setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking/EyeTrackingScripts/foraging")
img<-readJPEG("ng090ws.jpg")

#rastering the image, so it'd be readable in the graph later
g<-rasterGrob(img,interpolate=TRUE)

#density
ggplot(subset(FixationsV1_new, Task=='VisualSearch' & ParticipantID=='6_3_m2' & Trial==6), aes(x = PositionX, y = PositionY)) + 
  xlim(0,1920) + #limiting image to the resolution of the screen used in the experiment
  ylim(0, 1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) + #fitting the picture to the graph
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) + #plotting the actual heatmap, raster makes it smoother. ggplot can automatically define what color the datapoint bin has to be based on density
  scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradient(colours = jet.colors(10), trans="sqrt") #alpha is transparency. we say to use the 10 jet colors to distribute them between diffenerent density values, transition sqrt makes it smooth 

ggplot(subset(FixationsV2, Task=='VisualSearch' & ParticipantID=='6_3_m2' & Trial==6), aes(x = PositionX, y = PositionY)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) + #xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
  scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans="sqrt")


setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking/EyeTrackingScripts/foraging")
img2<-readJPEG("ng064ws.jpg")
g2<-rasterGrob(img2,interpolate=TRUE)

ggplot(subset(FixationsV2, Task=='VisualSearch' & ParticipantID=='1_1_f1' & Trial==4), aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g2, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) + #xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
  scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans="sqrt")


#Saccade amplitude <- Scanpaths
img3<-readJPEG("ng151ws.jpg")
g3<-rasterGrob(img3,interpolate = TRUE)

x<-subset(FixationsV2, Task=='VisualSearch' & ParticipantID=='3_1_f1' & Trial==9)
x<- x[order(x$Fixation),]

ggplot(x, aes(x = PositionX, y = 1081-PositionY, label = Fixation)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g3, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080)+
  geom_point(size = sqrt(x$Duration), alpha = 0.5, color="magenta") +
  geom_path(size = 1, alpha = 0.3) +
  geom_text(aes(label=Fixation,size= 5))
  



#Social engagement experiment:
#Pupil size <- growth plot 
#x=Trial Time
#y=Pupil size
#df=Samples
#grouping variables: g1 - Directiveness, g2 = Ostevsiveness
#geom_smooth <- line and confidence intervals
#facet_grid

setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking")
SamplesV2<-read.csv("SamplesV2.csv")
x<-subset(SamplesV2, Task=="SocialEngagement")
x<- x[order(x$TimeStamp),]

x$Directionality<-as.factor(x$Directionality)
ggplot(x, aes(x = TrialTime, y = PupilSize, color = Ostension)) +
  geom_smooth()+
  facet_grid(. ~ Directionality)
  
#ostension <- eye contact
```

