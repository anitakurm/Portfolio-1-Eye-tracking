---
title: "Eyetracking"
author: '"Anita Kurm"'
date: '5 февраля 2018 г '
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#libraries
pacman::p_load(readr,groupdata2,ggplot2,tidyverse,data.table)

#set wd
setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking")

#load the data, TAKES SOME TIME TO DOWNLOAD, DON'T DO IT IF NOT NECESSARY
#Samples=read_delim('eyetracking_2018_samples.txt',delim='\t')
#Fixations=read_delim('eyetracking_2018_fixations.txt',delim='\t')
#Saccades=read_delim('eyetracking_2018_saccades.txt',delim='\t')

#data files have data from both experiemts!

#data from v1. csv
FixationsV1=read_delim('FixationsV1.csv',delim=',')
SaccadesV1=read_delim('SaccadesV1.csv',delim=',')
SamplesV1=read_delim('SamplesV1.csv',delim=',')

#logfiles
setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking/PupilsLogs")
 
file_list <- list.files()
dataset<-NULL
 
#merge all of the log datafiles into one dataset
for (file in file_list){
       
  # if the merged dataset doesn't exist, create it
  if (!exists("dataset")){
    dataset <- read.table(file, header=TRUE, sep=",")
  }
   
  # if the merged dataset does exist, append to it
  if (exists("dataset")){
    temp_dataset <-read.table(file, header=TRUE, sep=",")
    dataset<-rbind(dataset, temp_dataset)
    rm(temp_dataset)
  }
 
}

#add 1 to X (trial)
dataset$X<-dataset$X+1
dataset$X<-dataset$Trial
dataset$X<-NULL

#change the names of the columns in the log files dataset
setnames(dataset,"subject", "ParticipantID")

#Merge logfiles
SaccadesV1_new<-merge(SaccadesV1,dataset, all = T)
FixationsV1_new<-merge(FixationsV1,dataset, all = T)
SamplesV1_new<-merge(SamplesV1,dataset,all=T)


#trials below 6, in search order 1 -> stars
#trials below 6, in serach order 2 -> count

SaccadesV1_new$SearchType<-NA
SaccadesV1_new$SearchType[SaccadesV1_new$Trial <6 & SaccadesV1_new$SearchOrder == 1] <- 'Star'
SaccadesV1_new$SearchType[SaccadesV1_new$Trial >=6 & SaccadesV1_new$SearchOrder == 1] <- 'Count'
SaccadesV1_new$SearchType[SaccadesV1_new$Trial <6 & SaccadesV1_new$SearchOrder == 2] <- 'Count'
SaccadesV1_new$SearchType[SaccadesV1_new$Trial >=6 & SaccadesV1_new$SearchOrder == 2] <- 'Star'

FixationsV1_new$SearchType<-NA
FixationsV1_new$SearchType[FixationsV1_new$Trial <6 & FixationsV1_new$SearchOrder == 1] <- 'Star'
FixationsV1_new$SearchType[FixationsV1_new$Trial >=6 & FixationsV1_new$SearchOrder == 1] <- 'Count'
FixationsV1_new$SearchType[FixationsV1_new$Trial <6 & FixationsV1_new$SearchOrder == 2] <- 'Count'
FixationsV1_new$SearchType[FixationsV1_new$Trial >=6 & FixationsV1_new$SearchOrder == 2] <- 'Star'

SamplesV1_new$SearchType<-NA
SamplesV1_new$SearchType[SamplesV1_new$Trial <6 & SamplesV1_new$SearchOrder == 1] <- 'Star'
SamplesV1_new$SearchType[SamplesV1_new$Trial >=6 & SamplesV1_new$SearchOrder == 1] <- 'Count'
SamplesV1_new$SearchType[SamplesV1_new$Trial <6 & SamplesV1_new$SearchOrder == 2] <- 'Count'
SamplesV1_new$SearchType[SamplesV1_new$Trial >=6 & SamplesV1_new$SearchOrder == 2] <- 'Star'


#new V1 datafiles are V2 datafiles in the folder
#always visualize and look at the data to spot abnormalities, etc.

#create a model to test the hypothesis: Visual search patterns are affaceted by task structure and goals
# predict the type of the task by variables of fixation duration, position, etc.d

#models
#model1<- Duration~SearchType+Trial+(1|ParticipantID)
#FAMILY=Gaussian(link=log) <-- data log trasnformation, helps to normalize skewed dataset

#so we have three models, use crossvalidation (3 folds) to see which one is the best

#make CROSS-VALIDATION
library(ggplot2)
library(dplyr)
library(lme4)
library(MuMIn)
library(lmerTest)
library(gstat)
library(stringr)
library(plyr)
library(caret)
library(modelr)
library(ModelMetrics)
library(Metrics)
library(tidyverse)
library(simr)
library(MASS)
library(pacman)

#Make variables into factors
FixationsV1_new$ParticipantID = as.factor(FixationsV1_new$ParticipantID)

  #folds first
Folds<- createFolds(unique(FixationsV1_new$ParticipantID),k=3)
Folds

#Create ID as numbers for use in folding
FixationsV1_new$fold_id = as.numeric(FixationsV1_new$ParticipantID)

#Preperations for loop - result lists and n reset
rmse_train = NULL
rmse_test = NULL
n=1


  #loop through each fold, train a model on the other folds and test it on the fold), thanks Peter!


#THE LOOP FOR THE BASIC MODEL  
for (i in Folds) {
  #Make a test dataset with one fold
  dtest_temp = subset(subset(FixationsV1_new, Task=="VisualSearch"), fold_id %in% i)
  #Make a training dataset with all other folds
  dtrain_temp = subset(subset(FixationsV1_new, Task=="VisualSearch"), !fold_id %in% i)
  
  #View(dtest_temp)
  #View(dtrain_temp)
  #Make a model on the training dataset
  Model_temp = lmer(Duration~SearchType+Trial+(1+SearchType+Trial|ParticipantID), data = dtrain_temp)
  
  #Check error between fit of training data and actual training data
  rmse_train[n] = Metrics :: rmse(dtrain_temp$Duration, fitted(Model_temp))
  
  #Check error between predicitions for test data and actual test data
  rmse_test[n] = Metrics :: rmse(dtest_temp$Duration, predict(Model_temp, dtest_temp, allow.new.levels=T)) 

    #Loop end and n+1
  n=n+1
}

#Get results
rmse_train
mean(rmse_train) #191.0751

rmse_test
mean(rmse_test) #201.8306


###########CROSS-VALIDATION################# doesn't work.. contrasts error

#Create list of the models to test
Ms = c("Duration~SearchType+Trial+(1+SearchType+Trial|ParticipantID)", 
       "Duration~SearchType*Trial+(1+SearchType*Trial|ParticipantID)",
       "Duration~SearchType+Fixation+(1+SearchType+Fixation|ParticipantID)",
       "Duration~SearchType+SearchOrder+(1+SearchType+SearchOrder|ParticipantID)"
       )

#Create lists for results
SCORES = as.data.frame(NULL)

#Create ID as numbers for use in folding
data$fold_id = as.numeric(FixationsV1_new$ParticipantID)

#Run Loop for all models
for (M in Ms) {
  #Create folds
  Folds = createFolds(unique(FixationsV1_new$fold_id), 3)
  #Preperations for loop - result lists and n reset
  rmse_train = NULL
  rmse_test = NULL
  n=1
  
  for (i in Folds) {
    #Make a test dataset with one fold
    dtest_temp = subset(subset(FixationsV1_new, Task=="VisualSearch"), fold_id %in% i)
    #Make a training dataset with all other folds
    dtrain_temp = subset(subset(FixationsV1_new, Task=="VisualSearch"), !fold_id %in% i)
    
    #View(dtest_temp)
    #View(dtrain_temp)
    #Make a model on the training dataset
    FixationsV1_new$ParticipantID=as.factor(FixationsV1_new$ParticipantID)
    model_temp = glmer(M, dtrain_temp, family = gaussian(link = log))
    
    #Check error between fit of training data and actual training data
    rmse_train[n] = Metrics :: rmse(dtrain_temp$Duration, fitted(model_temp))
    
    #Check error between predicitions for test data and actual test data
    rmse_test[n] = Metrics :: rmse(dtest_temp$Duration, predict(model_temp, dtest_temp, allow.new.levels=T)) 
  
      #Loop end and n+1
    n=n+1
  }
 #Create row with results from model
  NewRow = data.frame(Model = M, rmse_train = mean(rmse_train), rmse_test = mean(rmse_test))
  #Add to final dataframe with all models
  SCORES = rbind(SCORES, NewRow) 
}


#pupil size models - polinomial cubic model is probably the best (^3) for the social engagement task




#VISUAL REPRESENTATIONs
#Visual search experiment:
#Fixation duration <-heat maps, x and y = positions, colors = datapoints density 
setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking")
FixationsV2<- read.csv("FixationsV2.csv")
#libraries
library(jpeg)
library(grid)
library(ggplot2)

#choose the pallette
jet.colors <- colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan", "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))

#define the image for the graph background
setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking/EyeTrackingScripts/foraging")
img<-readJPEG("ng090ws.jpg")

#rastering the image, so it'd be readable in the graph later
g<-rasterGrob(img,interpolate=TRUE)

#density
ggplot(subset(FixationsV1_new, Task=='VisualSearch' & ParticipantID=='6_3_m2' & Trial==6), aes(x = PositionX, y = PositionY)) + 
  xlim(0,1920) + #limiting image to the resolution of the screen used in the experiment
  ylim(0, 1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) + #fitting the picture to the graph
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) + #plotting the actual heatmap, raster makes it smoother. ggplot can automatically define what color the datapoint bin has to be based on density
  scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradient(colours = jet.colors(10), trans="sqrt") #alpha is transparency. we say to use the 10 jet colors to distribute them between diffenerent density values, transition sqrt makes it smooth 

ggplot(subset(FixationsV2, Task=='VisualSearch' & ParticipantID=='6_3_m2' & Trial==6), aes(x = PositionX, y = PositionY)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) + #xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
  scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans="sqrt")


setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking/EyeTrackingScripts/foraging")
img2<-readJPEG("ng064ws.jpg")
g2<-rasterGrob(img2,interpolate=TRUE)

ggplot(subset(FixationsV2, Task=='VisualSearch' & ParticipantID=='1_1_f1' & Trial==4), aes(x = PositionX, y = 1081-PositionY)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g2, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080) + #xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf) +
  stat_density2d(geom="raster", aes(fill=..density.., alpha=sqrt(sqrt(..density..))), contour=FALSE, n=1000) +
  scale_alpha(range = c(0.1, 0.6)) + scale_fill_gradientn(colours = jet.colors(10), trans="sqrt")


#Saccade amplitude <- Scanpaths
img3<-readJPEG("ng151ws.jpg")
g3<-rasterGrob(img3,interpolate = TRUE)

x<-subset(FixationsV2, Task=='VisualSearch' & ParticipantID=='3_1_f1' & Trial==9)
x<- x[order(x$Fixation),]

ggplot(x, aes(x = PositionX, y = 1081-PositionY, label = Fixation)) +
  xlim(0,1920) +
  ylim(0, 1080) +
  annotation_custom(g3, xmin=-Inf, xmax=Inf, ymin=-0, ymax=1080)+
  geom_point(size = sqrt(x$Duration), alpha = 0.5, color="magenta") +
  geom_path(size = 1, alpha = 0.3) +
  geom_text(aes(label=Fixation,size= 5))
  



#Social engagement experiment:
#Pupil size <- growth plot 
#x=Trial Time
#y=Pupil size
#df=Samples
#grouping variables: g1 - Directiveness, g2 = Ostevsiveness
#geom_smooth <- line and confidence intervals
#facet_grid

setwd("C:/Users/Samsung/Desktop/expmeth/S4_Eyetracking")
SamplesV2<-read.csv("SamplesV2.csv")
x<-subset(SamplesV2, Task=="SocialEngagement")
x<- x[order(x$TimeStamp),]

x$Directionality<-as.factor(x$Directionality)
ggplot(x, aes(x = TrialTime, y = PupilSize, color = Ostension)) +
  geom_smooth()+
  facet_grid(. ~ Directionality)
  
#ostension <- eye contact
```

This R Markdown document is made interactive using Shiny. Unlike the more traditional workflow of creating static reports, you can now create documents that allow your readers to change the assumptions underlying your analysis and see the results immediately. 

To learn more, see [Interactive Documents](http://rmarkdown.rstudio.com/authoring_shiny.html).

## Inputs and Outputs

You can embed Shiny inputs and outputs in your document. Outputs are automatically updated whenever inputs change.  This demonstrates how a standard R plot can be made interactive by wrapping it in the Shiny `renderPlot` function. The `selectInput` and `sliderInput` functions create the input widgets used to drive the plot.

```{r eruptions, echo=FALSE}
inputPanel(
  selectInput("n_breaks", label = "Number of bins:",
              choices = c(10, 20, 35, 50), selected = 20),
  
  sliderInput("bw_adjust", label = "Bandwidth adjustment:",
              min = 0.2, max = 2, value = 1, step = 0.2)
)

renderPlot({
  hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks),
       xlab = "Duration (minutes)", main = "Geyser eruption duration")
  
  dens <- density(faithful$eruptions, adjust = input$bw_adjust)
  lines(dens, col = "blue")
})
```

## Embedded Application

It's also possible to embed an entire Shiny application within an R Markdown document using the `shinyAppDir` function. This example embeds a Shiny application located in another directory:

```{r tabsets, echo=FALSE}
shinyAppDir(
  system.file("examples/06_tabsets", package = "shiny"),
  options = list(
    width = "100%", height = 550
  )
)
```

Note the use of the `height` parameter to determine how much vertical space the embedded application should occupy.

You can also use the `shinyApp` function to define an application inline rather then in an external directory.

In all of R code chunks above the `echo = FALSE` attribute is used. This is to prevent the R code within the chunk from rendering in the document alongside the Shiny components.



